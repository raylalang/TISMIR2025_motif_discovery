run_name: lr_v1_nomnid_bps_beats
seed: 17
output_root: runs
motif:
  method: LR_V1
  # Raw note CSVs (no MNID / no oracle)
  csv_note_dir: datasets/Beethoven_motif-main/csv_notes_clean
  csv_label_dir: datasets/Beethoven_motif-main/csv_label
  motif_midi_dir: datasets/Beethoven_motif-main/motif_midi
  save_predictions: true
  num_workers: 4
  lr_config: null
  lr_params:
    embedding: learned
    # Update this to your JKUPDD-trained encoder checkpoint on the GPU server.
    learned_ckpt: runs/lr_v1_train_jkupdd_beats-YYYYMMDD-HHMMSS/encoder.pt
    learned_device: cuda
    learned_batch_size: 256
    learned_use_duration: false
    learned_input_repr: deltas
    learned_time_bin: 0.125
    learned_time_normalize: true
    segment_unit: beat
    # Optional: set beat_midi_dir only if your note CSV onsets are in seconds and you
    # want to map seconds -> beats via the MIDI tempo map.
    beat_midi_dir: null
    scale_lengths: [2.0, 4.0, 8.0, 16.0]
    hop_ratio: 0.25
    min_notes: 3
    retrieval:
      top_k: 0
      sim_threshold: 0.9
      max_time_iou: 0.25
      tempo_alpha: 1.0
      same_scale_only: true
    consolidate:
      iou_threshold: 0.5
      score_mode: centrality
